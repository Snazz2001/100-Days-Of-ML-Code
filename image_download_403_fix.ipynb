{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix HTTP 403 and 429 Errors When Downloading Images\n",
    "\n",
    "This notebook demonstrates how to download images using Python requests while avoiding common errors:\n",
    "- **HTTP 403 Forbidden**: Server blocks requests without proper headers\n",
    "- **HTTP 429 Too Many Requests**: Rate limiting from services like Wikimedia\n",
    "\n",
    "## The Problems\n",
    "\n",
    "### 1. HTTP 403 Forbidden\n",
    "```\n",
    "HTTPError: 403 Client Error: Forbidden\n",
    "```\n",
    "Cause: Missing or improper User-Agent header\n",
    "\n",
    "### 2. HTTP 429 Too Many Requests\n",
    "```\n",
    "HTTPError: 429 Client Error: Use thumbnail steps listed on https://w.wiki/GHai\n",
    "```\n",
    "Cause: Rate limiting by Wikimedia or other services\n",
    "\n",
    "## The Solution\n",
    "1. Add proper HTTP headers (especially User-Agent with identification)\n",
    "2. Implement retry logic with exponential backoff\n",
    "3. Handle redirects properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "# !pip install requests pillow matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Simple Solution with Retry Logic (RECOMMENDED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image_with_retry(url, max_retries=5, initial_delay=2):\n",
    "    \"\"\"\n",
    "    Download an image with retry logic for rate limiting.\n",
    "    \n",
    "    Args:\n",
    "        url (str): Image URL\n",
    "        max_retries (int): Maximum retry attempts\n",
    "        initial_delay (int): Initial delay in seconds for exponential backoff\n",
    "    \n",
    "    Returns:\n",
    "        PIL.Image: The downloaded image\n",
    "    \"\"\"\n",
    "    # Proper headers for Wikimedia and other services\n",
    "    # Note: Wikimedia requires identification in User-Agent\n",
    "    headers = {\n",
    "        'User-Agent': 'Python Image Downloader/1.0 (Educational/Research; Python requests)',\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "        'Accept-Language': 'en-US,en;q=0.9',\n",
    "        'Referer': 'https://www.google.com/',\n",
    "        'DNT': '1'\n",
    "    }\n",
    "    \n",
    "    delay = initial_delay\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"Attempt {attempt + 1}/{max_retries}...\")\n",
    "            \n",
    "            # Make request with headers\n",
    "            response = requests.get(url, headers=headers, timeout=15, allow_redirects=True)\n",
    "            \n",
    "            # Handle rate limiting (429) with exponential backoff\n",
    "            if response.status_code == 429:\n",
    "                if attempt < max_retries - 1:\n",
    "                    print(f\"⚠ Rate limited (429). Waiting {delay} seconds...\")\n",
    "                    time.sleep(delay)\n",
    "                    delay *= 2  # Exponential backoff: 2s, 4s, 8s, 16s...\n",
    "                    continue\n",
    "                else:\n",
    "                    raise Exception(f\"Rate limit exceeded after {max_retries} attempts\")\n",
    "            \n",
    "            # Check for other errors\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Open and return image\n",
    "            img = Image.open(BytesIO(response.content))\n",
    "            print(f\"✓ Success! Final URL: {response.url}\")\n",
    "            return img\n",
    "            \n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            if response.status_code == 429 and attempt < max_retries - 1:\n",
    "                continue\n",
    "            print(f\"✗ HTTP Error: {e}\")\n",
    "            raise\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                print(f\"⚠ Request failed. Retrying in {delay} seconds...\")\n",
    "                time.sleep(delay)\n",
    "                delay *= 2\n",
    "            else:\n",
    "                print(f\"✗ Request Error: {e}\")\n",
    "                raise\n",
    "    \n",
    "    raise Exception(\"Failed to download image after all retries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and display the image from bit.ly URL\n",
    "url = \"http://bit.ly/46xv3sL\"\n",
    "\n",
    "try:\n",
    "    img = download_image_with_retry(url)\n",
    "    \n",
    "    # Display the image\n",
    "    plt.figure(figsize=(12, 9))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title('Downloaded Image from Wikimedia')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nImage details:\")\n",
    "    print(f\"Size: {img.size}\")\n",
    "    print(f\"Mode: {img.mode}\")\n",
    "    \n",
    "    # Save the image\n",
    "    img.save('downloaded_image.png')\n",
    "    print(f\"✓ Saved to: downloaded_image.png\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Failed to download image: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Direct Wikimedia URL (Alternative)\n",
    "\n",
    "If you have the direct Wikimedia URL, you can use it directly with proper headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct Wikimedia URL (from the error message)\n",
    "wikimedia_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/Good_Smile_Company_offices_ladies.jpg/800px-Good_Smile_Company_offices_ladies.jpg\"\n",
    "\n",
    "try:\n",
    "    img = download_image_with_retry(wikimedia_url, max_retries=5, initial_delay=2)\n",
    "    \n",
    "    plt.figure(figsize=(12, 9))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title('Good Smile Company Office')\n",
    "    plt.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: Using Requests Session for Multiple Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_download_session():\n",
    "    \"\"\"\n",
    "    Create a requests session with proper headers for image downloads.\n",
    "    Useful for downloading multiple images efficiently.\n",
    "    \"\"\"\n",
    "    session = requests.Session()\n",
    "    session.headers.update({\n",
    "        'User-Agent': 'Python Image Downloader/1.0 (Educational/Research; Python requests)',\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "        'Accept-Language': 'en-US,en;q=0.9',\n",
    "        'Referer': 'https://www.google.com/',\n",
    "    })\n",
    "    return session\n",
    "\n",
    "# Create session\n",
    "session = create_download_session()\n",
    "\n",
    "# Download with session\n",
    "def download_with_session(session, url, delay=3):\n",
    "    \"\"\"Download image using a session with rate limiting delay.\"\"\"\n",
    "    time.sleep(delay)  # Respectful delay to avoid rate limits\n",
    "    response = session.get(url, timeout=15, allow_redirects=True)\n",
    "    response.raise_for_status()\n",
    "    return Image.open(BytesIO(response.content))\n",
    "\n",
    "# Example usage\n",
    "try:\n",
    "    img = download_with_session(session, \"http://bit.ly/46xv3sL\", delay=3)\n",
    "    plt.figure(figsize=(12, 9))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Errors\n",
    "\n",
    "### HTTP 403 Forbidden\n",
    "**Cause**: Server blocks requests without proper identification\n",
    "\n",
    "**Solution**: Add a User-Agent header that identifies your application\n",
    "\n",
    "### HTTP 429 Too Many Requests\n",
    "**Cause**: Rate limiting to prevent abuse\n",
    "\n",
    "**Solution**: \n",
    "1. Add delays between requests\n",
    "2. Implement exponential backoff (2s → 4s → 8s → 16s)\n",
    "3. Use a descriptive User-Agent so servers can contact you if needed\n",
    "\n",
    "### Wikimedia-Specific Requirements\n",
    "\n",
    "Wikimedia requires:\n",
    "- A User-Agent that identifies your bot/tool\n",
    "- Contact information in the User-Agent (recommended)\n",
    "- Respecting rate limits (they suggest waiting between requests)\n",
    "- Following their API guidelines: https://w.wiki/GHai\n",
    "\n",
    "Example of a good User-Agent for Wikimedia:\n",
    "```python\n",
    "'User-Agent': 'MyBot/1.0 (your@email.com) Python/3.x'\n",
    "```\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Always add a User-Agent header** - Identifies your application\n",
    "2. **Implement retry logic** - Handle temporary failures and rate limits\n",
    "3. **Use exponential backoff** - Gradually increase wait time between retries\n",
    "4. **Be respectful** - Don't hammer servers; add delays between requests\n",
    "5. **Handle redirects** - Use `allow_redirects=True` to follow URL shorteners\n",
    "6. **Add timeouts** - Prevent hanging requests with `timeout` parameter\n",
    "\n",
    "## Best Practices\n",
    "\n",
    "```python\n",
    "# ✓ Good: Respectful scraping\n",
    "headers = {'User-Agent': 'MyApp/1.0 (contact@example.com)'}\n",
    "time.sleep(2)  # Wait between requests\n",
    "response = requests.get(url, headers=headers, timeout=15)\n",
    "\n",
    "# ✗ Bad: Will likely get blocked\n",
    "for url in urls:\n",
    "    requests.get(url)  # No headers, no delays\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
